{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Restaurant Review Classification with Web Scraping"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/ping_linux/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["from requests_html import HTMLSession\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from IPython.display import Image \n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data Collection\n","We will use BeautifulSoup to collect the restaurant reviews and overall ratings from OpenTable websites, then store as Pandas df. "]},{"cell_type":"markdown","metadata":{},"source":["### Customer Reviews Scraping\n","Firstly, we search for the review section of website"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<img src=\"./image/review.png\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["Image(url=\"./image/review.png\") "]},{"cell_type":"markdown","metadata":{},"source":["Then we look into the inspect of this section"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<img src=\"./image/reviewfeature.png\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["Image(url=\"./image/reviewfeature.png\") "]},{"cell_type":"markdown","metadata":{},"source":["By inspecting the html code of the websites, we found that the review section is stored as 'span' and attributes with 'data-testid':'wrapper-tag', 'class':'t9JcvSL3Bsj1lxMSi3pz h_kb2PFOoyZe1skyGiz9 DUkDy8G7CgNvYcWgJYPN'. Also, we need to find the overall rating for each review as well, so we can get both information in this function."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def get_parser(soup, review_list, overall_rating_list):\n","    reviews = soup.find_all('span', {'data-testid':'wrapper-tag', 'class':'t9JcvSL3Bsj1lxMSi3pz h_kb2PFOoyZe1skyGiz9 DUkDy8G7CgNvYcWgJYPN'}) \n","    ratings = soup.find_all('span', {'class':'Q2DbumELlxH4s85dk8Mj'})\n","    for review in reviews:  # reviews is a list of items, need to use loop to process all searched items\n","        review = review.get_text(separator=' ')  # get text(comment) from each item\n","        review_list.append(review)\n","    for rating in ratings[::4]: \n","        rating = rating.get_text(separator=' ')\n","        overall_rating_list.append(rating)"]},{"cell_type":"markdown","metadata":{},"source":["Then, we tried to search for the pagination of this page, however the developer wrapped the page information into script section. So we cannot simply use BeautifulSoup to get the total page number. We will output all script section and look for \"page\" related words."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<img src=\"./image/totalpage.png\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["Image(url=\"./image/totalpage.png\") "]},{"cell_type":"markdown","metadata":{},"source":["In here we can first use BeautifulSoup to get script content, then use rule based method to sort for the number of total page"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def get_total_pages(url):\n","    session = HTMLSession()\n","    response = session.get(url)\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","    soup_find_total_page = soup.find_all('script') \n","    words = word_tokenize(str(soup_find_total_page[-3]))\n","    l = []\n","    flag = 0\n","    for i in words:\n","        if i =='totalPages':\n","            flag = 1\n","        if flag == 1:\n","            l.append(i)\n","    total_pages = int(l[2].replace(\":\", \"\"))\n","    return total_pages"]},{"cell_type":"markdown","metadata":{},"source":["Here we create a function to access all pages and scraping reviews from each page."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def get_reviews_from_all_pages(first_page_url, max_page):\n","    page = 1\n","    review_list = []\n","    overall_rating_list = []\n","    p1, p2 = first_page_url.split('page=')\n","\n","    while page!=(max_page+1):\n","        url = p1 + 'page=' + str(page)+ p2[1:]\n","        session = HTMLSession()\n","        response = session.get(url)\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","        get_parser(soup, review_list, overall_rating_list)        \n","        page += 1\n","    df = pd.DataFrame({'review': np.asarray(review_list), 'overall rating': np.asarray(overall_rating_list)})\n","    df['overall rating'] = df['overall rating'].astype(int) - 1  # label to ID, {'5 stars':4, '4 stars':3, ... , '1 stars': 0} \n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["We would like to create a url list to save our target restaurants, so we also need to create a function to process all urls.  \n","It will concat all reviews and save as one df."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def get_data_from_page_list(url_list):\n","    df_list = []\n","    for url in url_list:\n","        max_page = get_total_pages(url)\n","        df = get_reviews_from_all_pages(url, max_page)\n","        df_list.append(df)\n","    df = pd.concat(df_list)\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["Finally we can test the pipeline with one url list"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                 review  overall rating\n","0     The service was impeccable and the food was de...               4\n","1     Another grand slam for The Keg. Our group of 1...               4\n","2     My favourite steak house.\\nIf anyone wants a d...               4\n","3     Always a good meal and great value at the Keg ...               3\n","4     Always reliable. Good food, service and ambian...               4\n","...                                                 ...             ...\n","1726  Hostess was very welcoming, server was great a...               4\n","1727  Great decor and the ambiance was perfect. The ...               4\n","1728  Great experience!! Will definitely come back a...               4\n","1729  Excellent food and excellent service make for ...               4\n","1730  This is a great addition to the neighborhood. ...               4\n","\n","[1731 rows x 2 columns]\n"]}],"source":["url = ['https://www.opentable.ca/r/the-keg-steakhouse-and-bar-north-york?originId=bcc0b7a5-d42e-468c-8a2d-985968665f45&corrid=bcc0b7a5-d42e-468c-8a2d-985968665f45&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjowLCJuIjowfQ&page=1&sortBy=newestReview']\n","df = get_data_from_page_list(url)\n","print(df)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Review Classification with BERT\n","Here we will fine tune a pretrained model with our own data to perform the task."]},{"cell_type":"markdown","metadata":{},"source":["### Pretrained model from Amazon product reviews on Kaggle dataset\n","It is a pretrained model that predict reviews rating from 1 star to 5 stars, where the ID starts from 0 to 4. It will give a similar output to our case, where the output ratings is 1 to 5 stars as well. Also, we believe that the dataset gives similar content from product reviews to restaurant reviews, which will give good performance in Transfer Learning.  \n","We use 3 sentences to test the below model to see its expected output."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4 5 stars\n","0 1 star\n","3 4 stars\n"]}],"source":["pd.set_option('display.max_rows', None)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n","model = model.to(device)\n","\n","def forward_pass(sentence):\n","    inputs = tokenizer(sentence, return_tensors=\"pt\")\n","    inputs = inputs.to(device)\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","\n","    predicted_class_id = logits.argmax().item()\n","    pred = model.config.id2label[predicted_class_id]\n","    return predicted_class_id, pred\n","\n","def get_review_classification(df):\n","    df['prediction'] = ''\n","    for idx, review in df['review'].iteritems():\n","        pred = forward_pass(review)\n","        df.loc[idx, 'prediction'] = pred\n","    return df\n","\n","sentence = ['I love this product', 'I hate this product', 'It is not bad']\n","for i in sentence:\n","    predicted_class_id ,pred = forward_pass(i)\n","    print(predicted_class_id, pred)"]},{"cell_type":"markdown","metadata":{},"source":["Finally we selected a list of restaurants, including restaurants from high ratings to low ratings. Also, we selected one branch of our target restaurant and hopefully it can provide similar keywords to our model"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["url_list = [\n","                # rating above 4\n","                'https://www.opentable.ca/miller-tavern?originId=9ebce773-3b2e-48fc-93bc-8b79a06e95bc&corrid=9ebce773-3b2e-48fc-93bc-8b79a06e95bc&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjowLCJuIjowfQ&page=1&sortBy=newestReview',\n","                'https://www.opentable.ca/r/blue-blood-steakhouse-toronto?originId=1937513f-6bbc-4f51-b20e-444a14fea337&corrid=1937513f-6bbc-4f51-b20e-444a14fea337&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjowLCJuIjowfQ&page=1&sortBy=newestReview',\n","                # same restaurant but different location\n","                'https://www.opentable.ca/the-keg-steakhouse-and-bar-york-street?corrid=b977b24e-4643-4356-9441-763d4bebd7cf&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjoxLCJuIjowfQ&p=2&sd=2023-10-10T19%3A00%3A00&page=1&sortBy=newestReview',\n","                # rating 3.1\n","                'https://www.opentable.ca/r/chez-mal-manchester?page=1&sortBy=newestReview',\n","                # rating 2.9\n","                'https://www.opentable.ca/r/lookout-rooftop-boston?page=1&sortBy=newestReview',\n","                'https://www.opentable.ca/r/bar-31-shangri-la-the-shard-london?page=1&sortBy=newestReview',\n","                # rating 2.3\n","                'https://www.opentable.ca/pizza-rustica-restaurant-and-bar?originId=d084e009-f0b5-4a6f-8ba0-477c01aea935&corrid=d084e009-f0b5-4a6f-8ba0-477c01aea935&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjoxLCJuIjowfQ&p=2&sd=2023-10-10T19%3A00%3A00&page=1&sortBy=newestReview',\n","                # rating 1.9\n","                'https://www.opentable.ca/r/lime-an-american-cantina-denver?page=1&sortBy=newestReview',\n","                # rating 1.6\n","                'https://www.opentable.ca/r/bourgee-lakeside-grays?page=1&sortBy=newestReview',\n","                # rating 1.3\n","                'https://www.opentable.ca/r/chophouse-363-chino?page=1&sortBy=newestReview'\n","                ]\n","\n","eval_url = [\n","            'https://www.opentable.ca/r/the-keg-steakhouse-and-bar-north-york?originId=bcc0b7a5-d42e-468c-8a2d-985968665f45&corrid=bcc0b7a5-d42e-468c-8a2d-985968665f45&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjowLCJuIjowfQ&page=1&sortBy=newestReview'\n","            ]\n"]},{"cell_type":"markdown","metadata":{},"source":["We saved the train df and eval df as .csv files to save processing time in later training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = get_data_from_page_list(url_list)\n","eval = get_data_from_page_list(eval_url)\n","df.to_csv('./train.csv', index=False)\n","eval.to_csv('./eval.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Model Training"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b7c06fd7176408fa3f9b6f2e2d32ef1","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/13443 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9c72b3d43424453a47397b56d2906a0","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6722' max='6722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6722/6722 12:00, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.764800</td>\n","      <td>0.819088</td>\n","      <td>0.685797</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.638500</td>\n","      <td>0.889767</td>\n","      <td>0.693913</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from datasets import Dataset\n","import evaluate\n","import numpy as np\n","\n","def load_data(path, name):\n","    df = pd.read_csv(path)  \n","    df = df.rename(columns={'review': 'text', 'overall rating': 'label'})\n","    dataset = Dataset.from_pandas(df, split=name)\n","    return dataset\n","\n","def forward_pass(sentence):\n","    inputs = tokenizer(sentence, return_tensors=\"pt\")\n","    inputs = inputs.to(device)\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","\n","    predicted_class_id = logits.argmax().item()\n","    pred = model.config.id2label[predicted_class_id]\n","    return predicted_class_id, pred\n","\n","def get_review_classification(df):\n","    df['prediction'] = ''\n","    for idx, review in df['review'].iteritems():\n","        pred = forward_pass(review)\n","        df.loc[idx, 'prediction'] = pred\n","    return df\n","\n","def preprocess_function(examples):\n","    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)\n","\n","def compute_metrics(eval_pred):\n","    metric = evaluate.load('accuracy')\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","if __name__ == '__main__':\n","\n","    # pd.set_option('display.max_rows', None)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n","    model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n","    model = model.to(device)\n","    \n","    train_path = '/home/ping_linux/PycharmProjects/issac/restaurant_review/data/train.csv'\n","    eval_path = '/home/ping_linux/PycharmProjects/issac/restaurant_review/data/eval.csv'\n","    checkpoints_path = '/home/ping_linux/PycharmProjects/issac/restaurant_review/checkpoints'\n","\n","    train_dataset = load_data(train_path, name='train')\n","    eval_dataset = load_data(eval_path, name='eval')\n","    train_dataset = train_dataset.map(preprocess_function, batched=True)\n","    eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n","\n","    training_args = TrainingArguments(\n","        output_dir=checkpoints_path,\n","        evaluation_strategy = \"epoch\",\n","        save_strategy = \"epoch\",\n","        learning_rate=2e-5,\n","        per_device_train_batch_size=4,\n","        per_device_eval_batch_size=4,\n","        num_train_epochs=2,\n","        weight_decay=0.01,\n","        load_best_model_at_end=True,\n","        metric_for_best_model='accuracy'\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    trainer.train()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":4}
